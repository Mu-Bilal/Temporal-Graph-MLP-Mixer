project: GMM-GraphMSO  # For WandB
seed: null  # Whether fix the running seed to remove randomness

dataset:
  name: GraphMSO
  max_len: null
  train_size: 0.7
  val_size: 0.1
  horizon: 36
  window: 72
  stride: 1
  delay: 0
  EngRADchannel: 0

train:
  batch_size: 16  # Total graph mini-batch size
  epochs: 15  # Maximal number of epochs

  lr: 1e-3  # Base learning rate
  lr_patience: 10  # number of steps before reduce learning rate
  lr_decay: 0.5  # learning rate decay factor
  early_stop_patience: 15
  min_lr: 1.0e-5  # A lower bound on the learning rate.

  monitor: valid/loss  # Metric to monitor

  wd: 0  # L2 regularization, weight decay
  dropout_gnn: 0  # Dropout rate
  dropout_readout: 0  # Dropout rate for Readout
  dropout_patch_mixer: 0  # Dropout rate for patch MLPMixer
  dropout_node_mixer: 0  # Dropout rate for node MLPMixer

model:
  gnn_type: GINEConv  # GNN type used, see core.model_utils.pyg_gnn_wrapper for all options
  gMHA_type: MLPMixer  # GraphMLPMixer or graph-based multihead attention: [MLPMixer, Hadamard, Standard, Graph, Addictive, Kernel]
  
  nfeatures_patch: 128  # Number of features for patch mixer
  nfeatures_node: 64  # Number of features for node mixer

  nlayer_gnn: 2  # Number of gnn layers  FIXME: Check if receptive field is enough
  nlayer_patch_mixer: 2  # Number of mlp mixer layers
  nlayer_node_mixer: 3 # Number of mlp mixer layers

  nlayer_readout: 1  # Number of mlp layers for readout

  pool: mean  # Pooling type for generating graph/subgraph embedding from node embeddings
  residual: true  # Use residual connection

# Positional encoding options (currently not used directly, but needed for GraphPartitionTransform - TODO: Check and rm)
pos_enc:
  rw_dim: 16  # Random walk structural encoding
  lap_dim: 0  # Laplacian eigenvectors positional encoding
  patch_rw_dim: 8  # Patch random walk structural encoding
  patch_num_diff: -1  # Patch PE diffusion steps

# Metis patch extraction options
metis:
  enable: true  # Enable Metis partition (otherwise use random partition)
  online: false  # Enable data augmentation
  n_patches: 80  # The number of partitions
  num_hops: 1  # expanding patches with k hop neighbourhood
