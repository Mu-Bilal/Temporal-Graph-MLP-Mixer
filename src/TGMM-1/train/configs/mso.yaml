project: GMM-1  # For WandB
seed: null  # Whether fix the running seed to remove randomness

raw_data:  # HDTTS data pipeline settings
  name: mso_block_st  # dataset_failureMode
  connectivity:
    include_self: False
    layout: csr
  hparams:  # Needed here for synthetic dataset creation
    n_nodes: 100
    n_steps: 10000
    spatial_order: 3
    graph_generator: "knn3"
    noise: 0.0
    propagate_mask: False
    cached: True
    p_fault: 0
    p_noise: 0.05
    min_seq: 8
    max_seq: 48
    seed: 123
    max_neighbors: 5

dataset:
  max_len: null
  train_size: 0.7
  val_size: 0.1
  horizon: 36
  window: 72
  stride: 1
  delay: 0
  normalize: True

train:
  batch_size: 16  # Total graph mini-batch size
  accumulate_grad_batches: 1
  epochs: 60  # Maximal number of epochs

  # If this is True, missing (imputed) values are ignored when computing prediction loss (independent of metrics, see `logging` below)
  mask_loss: True  

  lr: 1e-3  # Base learning rate
  lr_patience: 10  # number of steps before reduce learning rate
  lr_decay: 0.5  # learning rate decay factor
  min_lr: 1.0e-5  # A lower bound on the learning rate.
  early_stop_patience: 5
  monitor: valid/loss  # Metric to monitor

  wd: 1e-4  # L2 regularization, weight decay
  dropout_gnn: 0.0  # Dropout rate
  dropout_patch_mixer: 0.0  # Dropout rate for patch MLPMixer
  dropout_node_mixer: 0.0  # Dropout rate for node MLPMixer
  dropout_readout: 0.0  # Dropout rate for Readout

model:
  gnn_type: GINEConv  # GNN type used, see core.model_utils.pyg_gnn_wrapper for all options
  gMHA_type: MLPMixer  # GraphMLPMixer or graph-based multihead attention: [MLPMixer, Hadamard, Standard, Graph, Addictive, Kernel]

  add_valid_mask: True  # Adds mask specifying if observation is valid (or invalid and hence imputed) to model input
  
  nfeatures_patch: 192  # Number of features for patch mixer
  nfeatures_node: 128  # Number of features for node mixer

  nlayer_gnn: 2  # Number of gnn layers  FIXME: Check if receptive field is enough
  nlayer_patch_mixer: 3  # Number of mlp mixer layers
  nlayer_node_mixer: 4 # Number of mlp mixer layers

  nlayer_readout: 1  # Number of mlp layers for readout

  pool: mean  # Pooling type for generating graph/subgraph embedding from node embeddings
  residual: True  # Use residual connection

# Positional encoding options (currently not used directly, but needed for GraphPartitionTransform - TODO: Check and rm)
pos_enc:
  rw_dim: 16  # Random walk structural encoding
  lap_dim: 0  # Laplacian eigenvectors positional encoding
  patch_rw_dim: 8  # Patch random walk structural encoding
  patch_num_diff: -1  # Patch PE diffusion steps

# Metis patch extraction options
metis:
  enable: True  # Enable Metis partition (otherwise use random partition)
  online: False  # Enable data augmentation
  n_patches: 50  # The number of partitions
  num_hops: 1  # expanding patches with k hop neighbourhood

logging:
  log_horizons: [12, 24, 36, "all"]
  # if this is True the matrics `stage/all-metric` will have invalid data (present in original dataset, imputed during cleaning) ignored. Independent of this, the metrics `stage/synthRm-metric` have synthetically missing data and originally missing data (both imputed during cleaning) ignored.
  ignore_invalid: True  
