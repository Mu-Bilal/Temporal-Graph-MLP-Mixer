project: GMM-1  # For WandB
seed: null  # Whether fix the running seed to remove randomness

raw_data:  # HDTTS data pipeline settings
  name: air_point  # dataset_failureMode
  mode:  # Part of missing data algo. Merged with configs/mode
    seed: 437   # also number of nodes
    min_seq: 4  # 4 hours
    max_seq: 12 # 12 hours
  connectivity:  # From HDTTS
    method: distance
    threshold: 0.1
    include_self: False
    layout: csr
  make_graph_connected: True
  hparams: {}

dataset:
  max_len: null
  train_size: 0.7
  val_size: 0.1
  horizon: 6
  window: 24
  stride: 1
  delay: 0
  normalize: True

train:
  batch_size: 4  # Total graph mini-batch size
  accumulate_grad_batches: 4
  epochs: 30  # Maximal number of epochs

  # If this is True, missing (imputed) values are ignored when computing prediction loss (independent of metrics, see `logging` below)
  mask_loss: True  

  lr: 1e-3  # Base learning rate
  lr_patience: 10  # number of steps before reduce learning rate
  lr_decay: 0.5  # learning rate decay factor
  min_lr: 1.0e-5  # A lower bound on the learning rate.
  early_stop_patience: 5
  monitor: valid/loss  # Metric to monitor

  wd: 1e-2  # L2 regularization, weight decay
  dropout_gnn: 0.3  # Dropout rate
  dropout_patch_mixer: 0.2  # Dropout rate for patch MLPMixer
  dropout_node_mixer: 0.2  # Dropout rate for node MLPMixer
  dropout_readout: 0.1  # Dropout rate for Readout

model:
  gnn_type: GINEConv  # GNN type used, see core.model_utils.pyg_gnn_wrapper for all options
  gMHA_type: MLPMixer  # GraphMLPMixer or graph-based multihead attention: [MLPMixer, Hadamard, Standard, Graph, Addictive, Kernel]

  add_valid_mask: True  # Adds mask specifying if observation is valid (or invalid and hence imputed) to model input
  
  nfeatures_patch: 128  # Number of features for patch mixer
  nfeatures_node: 128  # Number of features for node mixer

  nlayer_gnn: 2  # Number of gnn layers  FIXME: Check if receptive field is enough
  nlayer_patch_mixer: 3  # Number of mlp mixer layers
  nlayer_node_mixer: 4 # Number of mlp mixer layers

  nlayer_readout: 1  # Number of mlp layers for readout

  pool: mean  # Pooling type for generating graph/subgraph embedding from node embeddings
  residual: True  # Use residual connection

# Positional encoding options (currently not used directly, but needed for GraphPartitionTransform - TODO: Check and rm)
pos_enc:
  rw_dim: 16  # Random walk structural encoding
  lap_dim: 0  # Laplacian eigenvectors positional encoding
  patch_rw_dim: 8  # Patch random walk structural encoding
  patch_num_diff: -1  # Patch PE diffusion steps

# Metis patch extraction options
metis: # 1082 nodes in PvUS dataset
  enable: True  # Enable Metis partition (otherwise use random partition)
  online: False  # Enable data augmentation
  n_patches: 400  # The number of partitions
  num_hops: 1  # expanding patches with k hop neighbourhood

logging:
  log_horizons: [2, 4, 6, "all"]
  # if this is True the matrics `stage/all-metric` will have invalid data (present in original dataset, imputed during cleaning) ignored. Independent of this, the metrics `stage/synthRm-metric` have synthetically missing data and originally missing data (both imputed during cleaning) ignored.
  ignore_invalid: True  